{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce2a5a5",
   "metadata": {},
   "source": [
    "## Notebook to run Detect it easy and yara rules on the list of malware samples provided at /file/path/location and parse the results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6da5147-859e-4d36-9631-ddd67d17f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import yara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2af3aed0-e90b-4d0e-8672-8c0161390acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def die(samplefile: str, subdir: str) -> None:\n",
    "    \"\"\"Execute DIE tool to analyze a sample file.\n",
    "\n",
    "    Args:\n",
    "        samplefile (str): Path to the sample file to analyze.\n",
    "        subdir (str): Path to the directory where the analysis results will be stored.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filename = 'die_result.json'\n",
    "        diec_path = r\"C:\\Users\\ricewater\\Downloads\\die_win64_portable_3.09_x64\\diec.exe\"\n",
    "        path_to_file = os.path.join(subdir, filename)\n",
    "        if not os.path.exists(path_to_file):\n",
    "            # Create an empty dictionary to store results\n",
    "            data = {}\n",
    "        else:\n",
    "            # Load existing JSON data from the file\n",
    "            with open(path_to_file, 'r') as infile:\n",
    "                data = json.load(infile)\n",
    "        # Run DIE tool to get analysis results\n",
    "        result = subprocess.run([diec_path, '-d', '-e', '-j', samplefile], capture_output=True, text=True)\n",
    "        # Parse the output of the DIE tool\n",
    "        analysis_result = json.loads(result.stdout)\n",
    "        # Add the analysis result to the dictionary with the file name as key\n",
    "        data[os.path.basename(samplefile)] = analysis_result\n",
    "        # Write the updated data to the file\n",
    "        with open(path_to_file, 'w') as outfile:\n",
    "            json.dump(data, outfile, indent=4)\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "842a45bb-b280-4223-856d-9d88b9d8cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_yara_rule(samplefile: str, subdir: str) -> str:\n",
    "    \"\"\"Run YARA rule detection on the given sample file.\n",
    "\n",
    "    Args:\n",
    "        samplefile (str): Path to the sample file.\n",
    "        subdir (str): Path to the directory where the analysis results will be stored.\n",
    "\n",
    "    Returns:\n",
    "        str: Detected YARA rule.\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        yara_rule = r\"C:\\Users\\ricewater\\Downloads\\packer.yar\"\n",
    "        json_file_path = os.path.join(subdir, 'packer_yara_rule.json')\n",
    "        \n",
    "        if not os.path.exists(json_file_path):\n",
    "        # Create an empty dictionary to store results\n",
    "            data = {}\n",
    "        else:\n",
    "        # Load existing JSON data from the file\n",
    "            with open(path_to_file, 'r') as infile:\n",
    "                data = json.load(infile)  \n",
    "            \n",
    "        # Compile YARA rule\n",
    "        rules = yara.compile(filepath=yara_rule)\n",
    "        # Match YARA rules against sample file\n",
    "        matches = rules.match(samplefile)\n",
    "        # Extract matched rule names\n",
    "        matched_rules = [match.rule for match in matches]\n",
    "        # Join matched rule names into a single string\n",
    "        detected_rule = ', '.join(matched_rules)\n",
    "    \n",
    "        data[os.path.basename(samplefile)] = detected_rule\n",
    "\n",
    "        with open(json_file_path, 'w') as outfile:\n",
    "            json.dump(data, outfile, indent=4)\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d877d240-9243-4437-85f2-060250d401fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricewater\\AppData\\Local\\Temp\\ipykernel_4768\\1328734897.py:28: RuntimeWarning: too many matches for string $a0 in rule \"PENinja\"\n",
      "  matches = rules.match(samplefile)\n"
     ]
    }
   ],
   "source": [
    "#root_dir = r'C:\\Users\\ricewater\\Documents\\TempCrowdStrike'\n",
    "root_dir = r'C:\\Users\\ricewater\\Documents\\AV_2022_Dataset\\new_flattenDataset'\n",
    "\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            file_hash = os.path.basename(os.path.normpath(subdir))\n",
    "            if file_hash != file:\n",
    "                continue\n",
    "            sample_path = os.path.join(subdir, file)\n",
    "            #die(sample_path, subdir)\n",
    "            detect_yara_rule(sample_path, subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c127ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_status_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Iterate through a directory and its subdirectories to find and read 'die_result.json' files,\n",
    "    then identify the 'status' tag in each JSON file.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the directory to search in.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are file paths and values are the corresponding status tags.\n",
    "    \"\"\"\n",
    "    status_dict = {}\n",
    "    packed_count = 0\n",
    "\n",
    "    # Iterate through the directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file == 'die_result.json':\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    # Assuming there is only one key in the JSON data\n",
    "                    for key, value in data.items():\n",
    "                        status = value.get('status')\n",
    "                        if status == 'packed':\n",
    "                            packed_count += 1\n",
    "    \n",
    "    return packed_count\n",
    "\n",
    "# Example usage:\n",
    "root_dir = r'C:\\Users\\ricewater\\Documents\\AV_2022_Dataset\\new_flattenDataset'\n",
    "packed_count = find_status_in_directory(root_dir)\n",
    "print(packed_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62afbfdb-6901-449c-97f0-eab4e883e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique rules triggered across all files:\n",
      "UPXv20MarkusLaszloReiser\n",
      "ASPackv212AlexeySolodovnikov\n",
      "UPXV200V290MarkusOberhumerLaszloMolnarJohnReiser\n",
      "Armadillov1xxv2xx\n",
      "Borland\n",
      "UPX20030XMarkusOberhumerLaszloMolnarJohnReiser\n",
      "mpress_2_xx_x64\n",
      "upx_3\n",
      "PECompactv2xx\n",
      "DevCv5\n",
      "ASProtectV2XDLLAlexeySolodovnikov\n",
      "UPX290LZMAMarkusOberhumerLaszloMolnarJohnReiser\n",
      "PureBasicDLLNeilHodgson\n",
      "BobSoftMiniDelphiBoBBobSoft\n",
      "mpress_2_xx_x86\n",
      "pecompact2\n",
      "PureBasic4xNeilHodgson\n",
      "PellesC28x45xPelleOrinius\n",
      "UPXProtectorv10x2\n",
      "EnigmaProtector11X13XSukhovVladimirSergeNMarkin\n",
      "NETDLLMicrosoft\n",
      "NETexecutableMicrosoft\n",
      "MinGWGCC3x\n",
      "FSGv20\n",
      "D1S1Gv11betaD1N\n",
      "PECompactV2XBitsumTechnologies\n",
      "winrar_sfx\n",
      "PECompact2xxBitSumTechnologies\n",
      "PellesC300400450EXEX86CRTLIB\n",
      "623\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_unique_rules_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Iterate through a directory and its subdirectories to find and read 'packer_yara.json' files,\n",
    "    then extract the unique rules triggered across all the files.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the directory to search in.\n",
    "\n",
    "    Returns:\n",
    "        set: A set containing unique rules triggered across all files.\n",
    "    \"\"\"\n",
    "    unique_rules = set()\n",
    "    file_count_with_rules = 0\n",
    "\n",
    "    # Iterate through the directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file == 'packer_yara_rule.json':\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    for value in data.values():\n",
    "                        if value:\n",
    "                            rules = value.split(', ')\n",
    "                            unique_rules.update(rules)\n",
    "                            if len(rules) > 0:\n",
    "                                file_count_with_rules += 1\n",
    "    \n",
    "    return unique_rules, file_count_with_rules \n",
    "\n",
    "# Example usage:\n",
    "root_dir = r'C:\\Users\\ricewater\\Documents\\AV_2022_Dataset\\new_flattenDataset'\n",
    "unique_rules, file_count_with_rules = find_unique_rules_in_directory(root_dir)\n",
    "print(\"Unique rules triggered across all files:\")\n",
    "for rule in unique_rules:\n",
    "    print(rule)\n",
    "    \n",
    "print(file_count_with_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92a8c138-b8c1-4f02-9dd3-fd7216530c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files where 'die_result.json' indicates 'packed' status and 'packer_yara.json' has a non-empty value: 222\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def count_files_with_packed_status_and_non_empty_yara(directory_path):\n",
    "    \"\"\"\n",
    "    Count the files where 'die_result.json' indicates 'packed' status and 'packer_yara.json' has a non-empty value.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the directory to search in.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of files meeting the criteria.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through the directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file == 'die_result.json':\n",
    "                die_result_path = os.path.join(root, file)\n",
    "                packer_yara_path = os.path.join(root, 'packer_yara_rule.json')\n",
    "\n",
    "                # Check if both files exist\n",
    "                if os.path.exists(packer_yara_path) and os.path.exists(die_result_path):\n",
    "                    # Check die_result.json for 'packed' status\n",
    "                    with open(die_result_path, 'r') as f:\n",
    "                        die_result_data = json.load(f)\n",
    "                        for value in die_result_data.values():\n",
    "                            if value.get('status') == 'packed':\n",
    "                                # Check packer_yara.json for non-empty value\n",
    "                                with open(packer_yara_path, 'r') as f:\n",
    "                                    packer_yara_data = json.load(f)\n",
    "                                    if any(packer_yara_data.values()):\n",
    "                                        count += 1\n",
    "                                        break  # No need to continue checking other values\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Example usage:\n",
    "root_dir = r'C:\\Users\\ricewater\\Documents\\AV_2022_Dataset\\new_flattenDataset'\n",
    "count = count_files_with_packed_status_and_non_empty_yara(root_dir)\n",
    "print(\"Number of files where 'die_result.json' indicates 'packed' status and 'packer_yara.json' has a non-empty value:\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb3319-a13f-4529-b302-4b52b1048096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
